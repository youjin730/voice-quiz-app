import { router, useLocalSearchParams } from "expo-router";
import React, { useEffect, useState, useRef } from "react";
import {
  View,
  Text,
  StyleSheet,
  SafeAreaView,
  TouchableOpacity,
  Animated,
  Pressable,
  Vibration,
  Alert,
  ActivityIndicator,
} from "react-native";
import { MaterialCommunityIcons } from "@expo/vector-icons";
import { Audio } from "expo-av";
// âœ… API í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
import {
  startLongsSession,
  finishLongsSession,
  getScenarios,
} from "../api/training";
import client from "../api/client";

export default function LongFormScreen() {
  const [sessionId, setSessionId] = useState<number | null>(null);
  const [scenarioTitle, setScenarioTitle] = useState("ëœë¤ í›ˆë ¨ ì¤€ë¹„ ì¤‘...");

  const [callStatus, setCallStatus] = useState<"CONNECTED" | "ENDED">(
    "CONNECTED",
  );
  const [turn, setTurn] = useState<"AI" | "USER">("AI");
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(true); // ì²˜ìŒì—” ë¡œë”© ì¤‘

  const [aiLastText, setAiLastText] = useState("ì—°ê²° ì¤‘ì…ë‹ˆë‹¤...");
  const [isAiFinished, setIsAiFinished] = useState(false);

  const recordingRef = useRef<Audio.Recording | null>(null);
  const soundRef = useRef<Audio.Sound | null>(null);
  const micScale = useRef(new Animated.Value(1)).current;
  const waveAnim = useRef(new Animated.Value(1)).current;
  const [turnCount, setTurnCount] = useState(1); // ëŒ€í™” í„´ ë²ˆí˜¸ ê´€ë¦¬

  // 1. í™”ë©´ ì¼œì§€ìë§ˆì ì‹¤í–‰
  useEffect(() => {
    initRandomSession();
    return () => {
      if (soundRef.current) soundRef.current.unloadAsync();
    };
  }, []);

  // 2. íŒŒë™ ì• ë‹ˆë©”ì´ì…˜
  useEffect(() => {
    let loop: Animated.CompositeAnimation;
    if (turn === "AI" && callStatus === "CONNECTED") {
      loop = Animated.loop(
        Animated.sequence([
          Animated.timing(waveAnim, {
            toValue: 1.2,
            duration: 500,
            useNativeDriver: true,
          }),
          Animated.timing(waveAnim, {
            toValue: 1,
            duration: 500,
            useNativeDriver: true,
          }),
        ]),
      );
      loop.start();
    } else {
      waveAnim.setValue(1);
    }
    return () => loop?.stop();
  }, [turn, callStatus]);

  // âœ… [í•µì‹¬] ëœë¤ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ & ì„¸ì…˜ ì‹œì‘
  const initRandomSession = async () => {
    try {
      // 1) ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
      const perm = await Audio.requestPermissionsAsync();
      if (perm.status !== "granted") {
        Alert.alert("ì•Œë¦¼", "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
        router.back();
        return;
      }

      // 2) ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ëœë¤ ë½‘ê¸° ìœ„í•´)
      const scenariosRes: any = await getScenarios();
      const items =
        scenariosRes.data?.data?.items || scenariosRes.data?.items || [];

      if (items.length === 0) {
        Alert.alert("ì•Œë¦¼", "ì¤€ë¹„ëœ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.");
        router.back();
        return;
      }

      // 3) ëœë¤ ë½‘ê¸°! ğŸ²
      const randomIndex = Math.floor(Math.random() * items.length);
      const randomScenario = items[randomIndex];
      setScenarioTitle(randomScenario.title); // í™”ë©´ì— ì œëª© í‘œì‹œ

      console.log(
        `ğŸ² ë‹¹ì²¨ëœ ì‹œë‚˜ë¦¬ì˜¤: [${randomScenario.id}] ${randomScenario.title}`,
      );

      // 4) ë½‘íŒ ì‹œë‚˜ë¦¬ì˜¤ IDë¡œ ì„¸ì…˜ ì‹œì‘
      const sessionRes: any = await startLongsSession(randomScenario.id);
      const realSessionId = sessionRes.data?.data?.sessionId;

      if (realSessionId) {
        setSessionId(realSessionId);
        setAiLastText("ì—¬ë³´ì„¸ìš”? ì„œìš¸ì¤‘ì•™ì§€ê²€ ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤."); // ì´ˆê¸° ë©˜íŠ¸ (í˜¹ì€ ì„œë²„ì—ì„œ ë°›ê¸°)
        setIsLoading(false); // ë¡œë”© ë, í›ˆë ¨ ì‹œì‘!

        // 2ì´ˆ ë’¤ ì‚¬ìš©ì í„´
        setTimeout(() => setTurn("USER"), 2000);
      } else {
        throw new Error("ì„¸ì…˜ ID ì—†ìŒ");
      }
    } catch (error) {
      console.error("ëœë¤ ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨:", error);
      Alert.alert("ì˜¤ë¥˜", "í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
      router.back();
    }
  };

  // ... (ì´í•˜ ë…¹ìŒ, ì „ì†¡, ì¬ìƒ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
  // (ë³µì¡í•´ì§ˆê¹Œë´ ìƒëµí•˜ì§€ ì•Šê³ , ê¸°ì¡´ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”)

  const startRecording = async () => {
    try {
      if (turn === "AI" || isLoading || isAiFinished) return;
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY,
      );
      recordingRef.current = recording;
      setIsRecording(true);
      Vibration.vibrate(50);
      Animated.spring(micScale, {
        toValue: 0.9,
        useNativeDriver: true,
      }).start();
    } catch (err) {
      console.error(err);
    }
  };

  // app/training/long-form.tsx íŒŒì¼ ì•ˆì˜ stopRecordingAndSend í•¨ìˆ˜

  // app/training/long-form.tsx

  // (ì»´í¬ë„ŒíŠ¸ ìƒë‹¨ì— state ì¶”ê°€ í•„ìš”)

  // ... (ê¸°íƒ€ import ë™ì¼)

  const stopRecordingAndSend = async () => {
    if (!recordingRef.current) return;

    try {
      setIsRecording(false);
      setIsLoading(true);
      Animated.spring(micScale, { toValue: 1, useNativeDriver: true }).start();

      // 1. ë…¹ìŒ íŒŒì¼ ê²½ë¡œ í™•ë³´
      await recordingRef.current.stopAndUnloadAsync();
      const uri = recordingRef.current.getURI();
      recordingRef.current = null;

      if (!uri || !sessionId) {
        setIsLoading(false);
        return;
      }

      // 2. [íŒŒì¼ ì—…ë¡œë“œ] /api/uploads/voice í˜¸ì¶œ
      const voiceFormData = new FormData();
      voiceFormData.append("voiceFile", {
        uri: uri,
        type: "audio/m4a", // iOS ê¸°ì¤€, ì•ˆë“œë¡œì´ë“œëŠ” audio/mp4 í™•ì¸
        name: `voice_${Date.now()}.m4a`,
      } as any);

      console.log("ğŸ“¤ 1ë‹¨ê³„: ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ì‹œë„...");
      const uploadRes = await client.post("/api/uploads/voice", voiceFormData, {
        headers: { "Content-Type": "multipart/form-data" },
      });

      // ì„œë²„ ì‘ë‹µì—ì„œ íŒŒì¼ URL ì¶”ì¶œ
      const uploadedVoiceUrl = uploadRes.data?.data?.url;
      if (!uploadedVoiceUrl)
        throw new Error("íŒŒì¼ ì—…ë¡œë“œ í›„ URLì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");

      // 3. [ë©”ì‹œì§€ ì „ì†¡] /api/training/longs/messages í˜¸ì¶œ
      // ë°±ì—”ë“œ ìš”ì²­ëŒ€ë¡œ 'user_input' ë³€ìˆ˜ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
      const messagePayload = {
        sessionId: sessionId,
        turnNo: turnCount,
        inputMode: "voice",
        user_input: "ì‚¬ìš©ì ìŒì„± ì…ë ¥", // STTê°€ ëœë‹¤ë©´ ì—¬ê¸°ì— ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ë„£ìŠµë‹ˆë‹¤.
        userAudioUrl: uploadedVoiceUrl, // ì—…ë¡œë“œ ì„±ê³µí•œ S3 URL
        meta: { sttConfidence: null, durationMs: null },
        userProfileJson: JSON.stringify({
          user_profile: { name: "ì‚¬ìš©ì", scenario_type: "loan" },
        }),
      };

      console.log("ğŸ“¤ 2ë‹¨ê³„: ìµœì¢… ë©”ì‹œì§€ ì „ì†¡...", messagePayload);
      const response = await client.post(
        "/api/training/longs/messages",
        messagePayload,
      );

      // 4. AI ì‘ë‹µ ì²˜ë¦¬
      const resData = response.data?.data;
      if (resData) {
        const { aiText, status, aiAudioUrl, aiAudioBase64 } = resData;

        setTurnCount((prev) => prev + 1);
        if (aiText) setAiLastText(aiText);
        setTurn("AI");

        if (status === "finished") setIsAiFinished(true);

        // AI ìŒì„± ì¬ìƒ (Base64 ìš°ì„  ì²˜ë¦¬)
        if (aiAudioBase64) {
          await playAiVoice(
            `data:audio/mpeg;base64,${aiAudioBase64}`,
            status === "finished",
          );
        } else if (aiAudioUrl) {
          await playAiVoice(aiAudioUrl, status === "finished");
        }
      }
    } catch (error: any) {
      console.error(
        "ğŸ”¥ ì „ì†¡ ì‹¤íŒ¨ ìƒì„¸:",
        error.response?.data || error.message,
      );
      Alert.alert("í†µì‹  ì˜¤ë¥˜", "ì„œë²„ ì„¤ì •(S3 ë“±) í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.");
      setTurn("USER");
    } finally {
      setIsLoading(false);
    }
  };
  const playAiVoice = async (url: string, isFinished: boolean) => {
    try {
      if (soundRef.current) await soundRef.current.unloadAsync();
      const { sound } = await Audio.Sound.createAsync({ uri: url });
      soundRef.current = sound;
      await sound.playAsync();
      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          if (isFinished) handleHangUp();
          else setTurn("USER");
        }
      });
    } catch (e) {
      if (isFinished) handleHangUp();
      else setTurn("USER");
    }
  };

  const handleHangUp = async () => {
    try {
      setCallStatus("ENDED");
      if (soundRef.current) await soundRef.current.stopAsync();
      if (sessionId) await finishLongsSession(sessionId);
      setTimeout(() => {
        router.replace({ pathname: "/long-result", params: { sessionId } });
      }, 1500);
    } catch (e) {
      router.replace("/home");
    }
  };

  if (callStatus === "ENDED") {
    return (
      <View style={[styles.container, styles.endedContainer]}>
        <MaterialCommunityIcons name="phone-hangup" size={60} color="#EF4444" />
        <Text style={styles.endedText}>í†µí™” ì¢…ë£Œ</Text>
        <Text style={styles.endedSub}>í›ˆë ¨ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...</Text>
      </View>
    );
  }

  return (
    <SafeAreaView style={styles.container}>
      <View style={styles.header}>
        {/* âœ… ì œëª©ë„ ëœë¤ìœ¼ë¡œ ë½‘íŒ ê±¸ ë³´ì—¬ì¤Œ */}
        <Text style={styles.scenarioTitle}>{scenarioTitle}</Text>
        <Text style={styles.opponentName}>AI ë³´ì´ìŠ¤í”¼ì‹±ë²”</Text>
        <Text style={styles.timer}>ì‹¤ì „ í›ˆë ¨ ì¤‘</Text>
      </View>

      <View style={styles.visualizerContainer}>
        {turn === "AI" && (
          <Animated.View
            style={[styles.waveCircle, { transform: [{ scale: waveAnim }] }]}
          >
            <MaterialCommunityIcons
              name="account-voice"
              size={40}
              color="#fff"
            />
          </Animated.View>
        )}
        {isLoading && (
          <ActivityIndicator
            size="large"
            color="#22C55E"
            style={{ marginTop: 20 }}
          />
        )}

        <View style={styles.subtitleContainer}>
          <Text style={styles.subtitleText}>{aiLastText}</Text>
        </View>

        {!isRecording && !isLoading && turn === "USER" && !isAiFinished && (
          <Text style={styles.instructionText}>ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§í•˜ì„¸ìš”</Text>
        )}
      </View>

      <View style={styles.footer}>
        <Animated.View
          style={[styles.pttWrapper, { transform: [{ scale: micScale }] }]}
        >
          <Pressable
            onPressIn={startRecording}
            onPressOut={stopRecordingAndSend}
            disabled={turn === "AI" || isLoading || isAiFinished}
            style={({ pressed }) => [
              styles.pttButton,
              (turn === "AI" || isLoading || isAiFinished) &&
                styles.pttDisabled,
              isRecording && styles.pttActive,
            ]}
          >
            <MaterialCommunityIcons
              name={isRecording ? "microphone" : "microphone-outline"}
              size={40}
              color={
                turn === "AI" || isLoading || isAiFinished ? "#999" : "#fff"
              }
            />
            <Text
              style={[
                styles.pttText,
                (turn === "AI" || isLoading || isAiFinished) && {
                  color: "#999",
                },
              ]}
            >
              {isAiFinished
                ? "í†µí™” ì¢…ë£Œë¨"
                : turn === "AI"
                  ? "ìƒëŒ€ë°© ë§í•˜ëŠ” ì¤‘"
                  : isLoading
                    ? "ì—°ê²° ì¤‘..."
                    : isRecording
                      ? "ë§í•˜ëŠ” ì¤‘..."
                      : "ëˆ„ë¥´ê³  ë§í•˜ê¸°"}
            </Text>
          </Pressable>
        </Animated.View>
        <TouchableOpacity style={styles.hangUpButton} onPress={handleHangUp}>
          <MaterialCommunityIcons name="phone-hangup" size={32} color="#fff" />
        </TouchableOpacity>
      </View>
    </SafeAreaView>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: "#151C2C" },
  endedContainer: { alignItems: "center", justifyContent: "center" },
  endedText: { color: "#fff", fontSize: 24, fontWeight: "bold", marginTop: 20 },
  endedSub: { color: "#888", fontSize: 16, marginTop: 8 },
  header: { alignItems: "center", marginTop: 40 },
  scenarioTitle: { color: "#94A3B8", fontSize: 14, marginBottom: 8 },
  opponentName: {
    color: "#fff",
    fontSize: 28,
    fontWeight: "700",
    marginBottom: 8,
  },
  timer: { color: "#fff", fontSize: 16, fontWeight: "300", opacity: 0.8 },
  visualizerContainer: {
    flex: 1,
    alignItems: "center",
    justifyContent: "center",
    paddingHorizontal: 20,
  },
  waveCircle: {
    width: 120,
    height: 120,
    borderRadius: 60,
    backgroundColor: "rgba(239, 68, 68, 0.2)",
    borderWidth: 2,
    borderColor: "#EF4444",
    alignItems: "center",
    justifyContent: "center",
    marginBottom: 30,
  },
  subtitleContainer: {
    backgroundColor: "rgba(0,0,0,0.3)",
    padding: 16,
    borderRadius: 16,
    marginBottom: 20,
    width: "100%",
    alignItems: "center",
  },
  subtitleText: {
    color: "#fff",
    fontSize: 18,
    fontWeight: "600",
    textAlign: "center",
    lineHeight: 26,
  },
  instructionText: { color: "#64748B", fontSize: 16, marginTop: 10 },
  footer: {
    paddingBottom: 50,
    alignItems: "center",
    paddingHorizontal: 30,
    gap: 30,
  },
  pttWrapper: { width: "100%", alignItems: "center" },
  pttButton: {
    width: "100%",
    height: 80,
    borderRadius: 24,
    backgroundColor: "#334155",
    flexDirection: "row",
    alignItems: "center",
    justifyContent: "center",
    gap: 12,
    borderWidth: 1,
    borderColor: "rgba(255,255,255,0.1)",
  },
  pttActive: { backgroundColor: "#22C55E", borderColor: "#22C55E" },
  pttDisabled: { opacity: 0.6 },
  pttText: { fontSize: 18, fontWeight: "700", color: "#fff" },
  hangUpButton: {
    width: 70,
    height: 70,
    borderRadius: 35,
    backgroundColor: "#EF4444",
    alignItems: "center",
    justifyContent: "center",
  },
});
